
1.爬虫：通过编写程序来获取到互联网上的资源
需求：用程序模拟浏览器，输入一个网址，从该网址中获取到资源或者内容
获取到网址内容后要.read
但是需要解码：decode（“utf-8”）
格式
urlopen(url).read().decode("utf-8")
这个时候得到的是网站前端代码
可以
f=open("xxx.hmtl","w",encoding="utf-8")
f.write(上面代码）
此后就可以将其打开



1服务器渲染：在服务器那边直接把数据和HTML整合到一起，统一返回给浏览器
在页面源代码中看得到数据
2客户端渲染：第一次请求只要一个HTML骨架，第二次请求拿到数据，进行数据展示
在页面源代码中，看不到数据

熟练使用浏览器抓包工具
使用F12
然后回车页面网址
可以得到客户端渲染的数据

请求：
请求行：请求方式（get/post）请求url地址，协议
请求头：放一些服务器使用的附加信息
请求体：一般放一些请求参数


响应：
1状态行：协议，状态码
（比如说404）
2响应头：放进客户端需要使用的一些附加信息
3响应体：服务器放回真正的客户端时需要的内容



请求头：

GET：显示提交
变量名=requests.get(url,headers=变量名)得到的变量表示发送requests中get请求得到的东西
其中传参使用的形参名叫做params

POST:隐示提交
resp=requests.post(url,data=dat)，发送post请求，所发送的参数必须通过字典传递，
可以将服务器发送的内容处理成为json文件形式直接读取
使用json文件形式，可以采用键值对的形式对文件进行直接的整理

请求头
headers：{
}
里面需要加上user——agent（需要加上双引号）
里面的内容要从网站里面获取
在访问网站结束后，需要加上resp.close() 保证访问可以及时结束


